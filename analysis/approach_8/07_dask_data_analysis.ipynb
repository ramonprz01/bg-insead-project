{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis at Scale on Filtered Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help you get answers for the following measures.\n",
    "\n",
    "- **Measure 1:** The new version Relative usage of up-ward & down-ward terms\n",
    "- **Measure 2:** Does the job ad list another job title and tells us who reports to whom?\n",
    "    1. This measure needs to take every keyword above and export the next 7 words in the job ad following it, if any (return NaN otherwise), as a separate column, one for each of the dummies above. \n",
    "- **Measure 3:** How many unique job titles are there in the firm?\n",
    "    1. For each firm-week, firm-year and firm-full-sample, calculate the number of unique (we should have 9 variables for each firm with the number of unique values that either don’t vary within firm, vary within firms each year or vary within firms each week):\n",
    "        - CleanJobTitle\n",
    "        - ConsolidatedJobTitle\n",
    "        - CanonJobTitle\n",
    "- **Measure 4:** Managerial intensity?\n",
    "    1. For each firm-location-week-occupationbelow, calculate the number of job ads with the following job codes:\n",
    "    2. For each firm-location-week-alloccups, calculate also the number of job ads with the following job code:\n",
    "        - Everything starting with ‘11’\n",
    "    3. For each firm-location-week, calculate also the total number of job ads posted by that firm regardless of the occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to keep in mind before running the code in this notebook.\n",
    "\n",
    "- This notebook assumes you already ran the notebook called \"06_dask_get_companies.ipynb\", which gets you the filtered dataset from the cleaned sample. Conversely, you already have access to this dataset\n",
    "- You will be using dask dataframes for distributed computing in your local machine. You can think of these dataframes as lazy pandas (no pun intended)\n",
    "- Depending on how you modify this notebook and decide to use it moving forward, please keep in mind that you will be generating quite a few files at the end of this notebook so make sure to tweak the function at the end of the notebook to adjust the files you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, dask.dataframe as dd, dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re, csv, os\n",
    "import numpy as np\n",
    "from dask import delayed, persist\n",
    "from dask.distributed import Client\n",
    "from glob import glob\n",
    "from typing import List, Union\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "csv.field_size_limit(10000000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the path where your filtered data lives and put it below in `path` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ramonperez/Dropbox/Burning Glass/Data/companies_76k/filtered_data_07/'\n",
    "path_out = '/Users/ramonperez/Dropbox/Burning Glass/Analysis/approach_8/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two lists contain the names of the clean variables from the previous steps and the data types we will be using to read them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['JobID', 'CleanJobTitle', 'CanonCity', 'CanonState', 'Source', 'Latitude', \n",
    "             'Longitude', 'CanonJobTitle', 'CanonCounty', 'MSA', 'LMA', 'InternshipFlag',\n",
    "             'ConsolidatedONET', 'CanonSkillClusters', 'CanonSkills', 'CanonMinimumDegree',\n",
    "             'CanonRequiredDegrees', 'MinExperience', 'ConsolidatedInferredNAICS', 'BGTOcc',\n",
    "             'YearsOfExperience', 'CanonJobHours', 'CanonJobType', 'CanonPostalCode', \n",
    "             'CanonYearsOfExperienceCanonLevel', 'CanonYearsOfExperienceLevel', 'ConsolidatedTitle',\n",
    "             'BGTSubOcc', 'ConsolidatedDegreeLevels', 'MinDegreeLevel', 'EmployerClean',\n",
    "             'clean_text', 'JobDate']\n",
    "\n",
    "dtypes={'CanonSkills': np.str, 'Latitude': np.float32, 'JobID': np.str, 'CanonJobTitle': np.str,\n",
    "        'CanonYearsOfExperienceLevel': np.str, 'Longitude': np.float32, 'CanonJobType': np.str, \n",
    "        'CleanJobTitle': np.str, 'ConsolidatedInferredNAICS': np.str, 'CanonRequiredDegrees': np.str,\n",
    "        'YearsOfExperience': np.str, 'CanonCity': np.str, 'CanonCounty': np.str, 'CanonJobHours': np.str,\n",
    "        'CanonState': np.str, 'ConsolidatedONET': np.str, 'MSA': np.str, 'CanonMinimumDegree': np.str,\n",
    "        'ConsolidatedDegreeLevels': np.str, 'BGTSubOcc': np.str, 'ConsolidatedTitle': np.str,\n",
    "        'CanonSkillClusters': np.str, 'Language': np.str, 'JobDate': np.str,\n",
    "        'MinDegreeLevel': np.str, 'LMA': np.str, 'MinExperience': np.str, 'CanonPostalCode': np.str,\n",
    "        'InternshipFlag': np.bool_, 'Source': np.str, 'BGTOcc': np.str, 'CanonYearsOfExperienceCanonLevel': np.str}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting in the below cell we will begin creating a directed acyclical graph using dask. This means that we will be making barely any computations until the very end of the notebook.\n",
    "\n",
    "The snippet below will help us read in the amount files in the directory specified above. Make sure to place the wildcard in the appropriate spot, otherwise you will not be able to read in the data.\n",
    "\n",
    "Parameters used:\n",
    "\n",
    "- `engine='python'`\n",
    "- `dtype=dtypes`: our list of data types above\n",
    "- `assume_missing=True`: Yes, there might be some edge cases of missing values not taken care of in our previous step.\n",
    "- `error_bad_lines=False`: We don't want any bad line in our data so let's allow dask to tell us.\n",
    "- `blocksize=None`: Dask usually tries to read in a small sample of the data and makes inferences as to what data type belongs to what. Because in our case some of the job descriptions have quite large amounts of text per observation, dask won't play it nice with our use case and will most likely misinterpret the commas in some of the values in the `JobText` column. Because of this, we will read in every block without making inferences. Luckily, since in the previous step we created small enough files, even reading the full file in will end up being blazingly fast.\n",
    "- `usecols=col_names`: our list of columns above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CanonCity</th>\n",
       "      <th>CanonState</th>\n",
       "      <th>CleanJobTitle</th>\n",
       "      <th>JobDate</th>\n",
       "      <th>JobID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>CanonPostalCode</th>\n",
       "      <th>CanonCounty</th>\n",
       "      <th>LMA</th>\n",
       "      <th>MSA</th>\n",
       "      <th>CanonJobTitle</th>\n",
       "      <th>ConsolidatedONET</th>\n",
       "      <th>InternshipFlag</th>\n",
       "      <th>Source</th>\n",
       "      <th>CanonSkillClusters</th>\n",
       "      <th>CanonSkills</th>\n",
       "      <th>CanonMinimumDegree</th>\n",
       "      <th>CanonRequiredDegrees</th>\n",
       "      <th>MinExperience</th>\n",
       "      <th>ConsolidatedInferredNAICS</th>\n",
       "      <th>BGTOcc</th>\n",
       "      <th>CanonJobHours</th>\n",
       "      <th>CanonJobType</th>\n",
       "      <th>CanonYearsOfExperienceCanonLevel</th>\n",
       "      <th>CanonYearsOfExperienceLevel</th>\n",
       "      <th>ConsolidatedDegreeLevels</th>\n",
       "      <th>ConsolidatedTitle</th>\n",
       "      <th>MinDegreeLevel</th>\n",
       "      <th>BGTSubOcc</th>\n",
       "      <th>YearsOfExperience</th>\n",
       "      <th>EmployerClean</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=50</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from-delayed, 150 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               CanonCity CanonState CleanJobTitle JobDate   JobID Latitude Longitude CanonPostalCode CanonCounty     LMA     MSA CanonJobTitle ConsolidatedONET InternshipFlag  Source CanonSkillClusters CanonSkills CanonMinimumDegree CanonRequiredDegrees MinExperience ConsolidatedInferredNAICS  BGTOcc CanonJobHours CanonJobType CanonYearsOfExperienceCanonLevel CanonYearsOfExperienceLevel ConsolidatedDegreeLevels ConsolidatedTitle MinDegreeLevel BGTSubOcc YearsOfExperience EmployerClean clean_text\n",
       "npartitions=50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "                  object     object        object  object  object  float32   float32          object      object  object  object        object           object           bool  object             object      object             object               object        object                    object  object        object       object                           object                      object                   object            object         object    object            object        object     object\n",
       "                     ...        ...           ...     ...     ...      ...       ...             ...         ...     ...     ...           ...              ...            ...     ...                ...         ...                ...                  ...           ...                       ...     ...           ...          ...                              ...                         ...                      ...               ...            ...       ...               ...           ...        ...\n",
       "...                  ...        ...           ...     ...     ...      ...       ...             ...         ...     ...     ...           ...              ...            ...     ...                ...         ...                ...                  ...           ...                       ...     ...           ...          ...                              ...                         ...                      ...               ...            ...       ...               ...           ...        ...\n",
       "                     ...        ...           ...     ...     ...      ...       ...             ...         ...     ...     ...           ...              ...            ...     ...                ...         ...                ...                  ...           ...                       ...     ...           ...          ...                              ...                         ...                      ...               ...            ...       ...               ...           ...        ...\n",
       "                     ...        ...           ...     ...     ...      ...       ...             ...         ...     ...     ...           ...              ...            ...     ...                ...         ...                ...                  ...           ...                       ...     ...           ...          ...                              ...                         ...                      ...               ...            ...       ...               ...           ...        ...\n",
       "Dask Name: from-delayed, 150 tasks"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = dd.read_csv(os.path.join(path, 'da*.csv'), \n",
    "                 engine='python',\n",
    "                 dtype=dtypes,\n",
    "                 assume_missing=True,\n",
    "                 error_bad_lines=False,\n",
    "                 blocksize=None,\n",
    "                 usecols=col_names,\n",
    "                )\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful when checking the `.head()` or `.tail()` of the datasets you will be working with. Depending on how much data you are trying to view, especially if it doesn't fit into memory, this could take anywhere between 2 minutes to an hour or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 85.4 ms, sys: 90 ms, total: 175 ms\n",
      "Wall time: 189 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CanonCity</th>\n",
       "      <th>CanonState</th>\n",
       "      <th>CleanJobTitle</th>\n",
       "      <th>JobDate</th>\n",
       "      <th>JobID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>CanonPostalCode</th>\n",
       "      <th>CanonCounty</th>\n",
       "      <th>LMA</th>\n",
       "      <th>MSA</th>\n",
       "      <th>CanonJobTitle</th>\n",
       "      <th>ConsolidatedONET</th>\n",
       "      <th>InternshipFlag</th>\n",
       "      <th>Source</th>\n",
       "      <th>CanonSkillClusters</th>\n",
       "      <th>CanonSkills</th>\n",
       "      <th>CanonMinimumDegree</th>\n",
       "      <th>CanonRequiredDegrees</th>\n",
       "      <th>MinExperience</th>\n",
       "      <th>ConsolidatedInferredNAICS</th>\n",
       "      <th>BGTOcc</th>\n",
       "      <th>CanonJobHours</th>\n",
       "      <th>CanonJobType</th>\n",
       "      <th>CanonYearsOfExperienceCanonLevel</th>\n",
       "      <th>CanonYearsOfExperienceLevel</th>\n",
       "      <th>ConsolidatedDegreeLevels</th>\n",
       "      <th>ConsolidatedTitle</th>\n",
       "      <th>MinDegreeLevel</th>\n",
       "      <th>BGTSubOcc</th>\n",
       "      <th>YearsOfExperience</th>\n",
       "      <th>EmployerClean</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Cypress</td>\n",
       "      <td>CA</td>\n",
       "      <td>Senior Healthcare Analyst - Sas Programming Sk...</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339756230</td>\n",
       "      <td>33.815399</td>\n",
       "      <td>-118.037003</td>\n",
       "      <td>90630</td>\n",
       "      <td>Orange</td>\n",
       "      <td>DV064204|MT063110</td>\n",
       "      <td>31080: Metropolitan Statistical Area|348: Comb...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29207100</td>\n",
       "      <td>False</td>\n",
       "      <td>Company from Job Board</td>\n",
       "      <td>Health Care: Clinical Data Management;Speciali...</td>\n",
       "      <td>{'Clinical Data Review': 'Health Care: Clinica...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>524113</td>\n",
       "      <td>29-2071.96</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>permanent</td>\n",
       "      <td>1-6</td>\n",
       "      <td>mid</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Senior Healthcare Analyst, Sas</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Healthcare Analyst</td>\n",
       "      <td>5-6 years</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>Sr. Healthcare Analyst - SAS programming skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>CA</td>\n",
       "      <td>Iridesse Sales Professional</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339820992</td>\n",
       "      <td>37.352901</td>\n",
       "      <td>-121.953003</td>\n",
       "      <td>95052</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>MT064194</td>\n",
       "      <td>41940: Metropolitan Statistical Area</td>\n",
       "      <td>Sales Professional</td>\n",
       "      <td>41203100</td>\n",
       "      <td>False</td>\n",
       "      <td>Company from Job Board</td>\n",
       "      <td>Marketing and Public Relations: Customer Relat...</td>\n",
       "      <td>{'Client Base Retention': 'Marketing and Publi...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>448310</td>\n",
       "      <td>41-2031.00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1-6</td>\n",
       "      <td>mid</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Sales Professional</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Retail Sales Associate (General)</td>\n",
       "      <td>minimum of 2 years</td>\n",
       "      <td>Tiffany &amp; Co.</td>\n",
       "      <td>Careers  Iridesse Sales Professional  Req #:  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>Director, Distribution Center Operations</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339820871</td>\n",
       "      <td>37.779800</td>\n",
       "      <td>-122.417000</td>\n",
       "      <td>94175</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>DV064188|MT064186</td>\n",
       "      <td>41860: Metropolitan Statistical Area|488: Comb...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11102100</td>\n",
       "      <td>False</td>\n",
       "      <td>Company from Job Board</td>\n",
       "      <td>Finance: Budget Management;Specialized Skills|...</td>\n",
       "      <td>{'Budgeting': 'Finance: Budget Management;Spec...</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>13</td>\n",
       "      <td>448140</td>\n",
       "      <td>11-1021.91</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>permanent</td>\n",
       "      <td>6+</td>\n",
       "      <td>high</td>\n",
       "      <td>16</td>\n",
       "      <td>Director, Distribution,Operations</td>\n",
       "      <td>16</td>\n",
       "      <td>Retail Operations Supervisor</td>\n",
       "      <td>10+ years|At least 5 years</td>\n",
       "      <td>Levi Strauss</td>\n",
       "      <td>Job Search Engine - Job Blogs  Friday, October...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>Financial Services Professional</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>360306555</td>\n",
       "      <td>25.794901</td>\n",
       "      <td>-80.127800</td>\n",
       "      <td>33159</td>\n",
       "      <td>Miami-Dade</td>\n",
       "      <td>DV123312|MT123310</td>\n",
       "      <td>33100: Metropolitan Statistical Area|370: Comb...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>41303102</td>\n",
       "      <td>False</td>\n",
       "      <td>Job Board</td>\n",
       "      <td>Sales: Solution Sales Engineering;Specialized ...</td>\n",
       "      <td>{'Consultative Sales': 'Sales: Solution Sales ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>6233</td>\n",
       "      <td>41-3031.00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Financial Services Professional</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Financial Services Representative</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Brookdale Senior Living</td>\n",
       "      <td>-  Levin Financial Group of Massmutual -  Tamp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Lorton</td>\n",
       "      <td>VA</td>\n",
       "      <td>District Sales Manager</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>38009597932</td>\n",
       "      <td>38.704102</td>\n",
       "      <td>-77.227997</td>\n",
       "      <td>22199</td>\n",
       "      <td>Fairfax</td>\n",
       "      <td>DV114789|MT114790</td>\n",
       "      <td>47900: Metropolitan Statistical Area|548: Comb...</td>\n",
       "      <td>District Sales Manager</td>\n",
       "      <td>11202200</td>\n",
       "      <td>False</td>\n",
       "      <td>Company from Job Board</td>\n",
       "      <td>Common Skills|Specialized Skills|Analysis: Bus...</td>\n",
       "      <td>{'Communication Skills': 'Common Skills', 'Com...</td>\n",
       "      <td>Higher Secondary Certificate</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>511110</td>\n",
       "      <td>11-2022.00</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>permanent</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>16|12</td>\n",
       "      <td>District Sales Manager</td>\n",
       "      <td>12</td>\n",
       "      <td>Territory / Regional Sales Manager</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>USA Today</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CanonCity CanonState  \\\n",
       "83        Cypress         CA   \n",
       "84    Santa Clara         CA   \n",
       "85  San Francisco         CA   \n",
       "86          Miami         FL   \n",
       "87         Lorton         VA   \n",
       "\n",
       "                                        CleanJobTitle     JobDate  \\\n",
       "83  Senior Healthcare Analyst - Sas Programming Sk...  2007-12-31   \n",
       "84                        Iridesse Sales Professional  2007-12-31   \n",
       "85           Director, Distribution Center Operations  2007-12-31   \n",
       "86                    Financial Services Professional  2007-12-31   \n",
       "87                             District Sales Manager  2007-12-31   \n",
       "\n",
       "          JobID   Latitude   Longitude CanonPostalCode    CanonCounty  \\\n",
       "83    339756230  33.815399 -118.037003           90630         Orange   \n",
       "84    339820992  37.352901 -121.953003           95052    Santa Clara   \n",
       "85    339820871  37.779800 -122.417000           94175  San Francisco   \n",
       "86    360306555  25.794901  -80.127800           33159     Miami-Dade   \n",
       "87  38009597932  38.704102  -77.227997           22199        Fairfax   \n",
       "\n",
       "                  LMA                                                MSA  \\\n",
       "83  DV064204|MT063110  31080: Metropolitan Statistical Area|348: Comb...   \n",
       "84           MT064194               41940: Metropolitan Statistical Area   \n",
       "85  DV064188|MT064186  41860: Metropolitan Statistical Area|488: Comb...   \n",
       "86  DV123312|MT123310  33100: Metropolitan Statistical Area|370: Comb...   \n",
       "87  DV114789|MT114790  47900: Metropolitan Statistical Area|548: Comb...   \n",
       "\n",
       "             CanonJobTitle ConsolidatedONET  InternshipFlag  \\\n",
       "83                 Unknown         29207100           False   \n",
       "84      Sales Professional         41203100           False   \n",
       "85                 Unknown         11102100           False   \n",
       "86                 Unknown         41303102           False   \n",
       "87  District Sales Manager         11202200           False   \n",
       "\n",
       "                    Source                                 CanonSkillClusters  \\\n",
       "83  Company from Job Board  Health Care: Clinical Data Management;Speciali...   \n",
       "84  Company from Job Board  Marketing and Public Relations: Customer Relat...   \n",
       "85  Company from Job Board  Finance: Budget Management;Specialized Skills|...   \n",
       "86               Job Board  Sales: Solution Sales Engineering;Specialized ...   \n",
       "87  Company from Job Board  Common Skills|Specialized Skills|Analysis: Bus...   \n",
       "\n",
       "                                          CanonSkills  \\\n",
       "83  {'Clinical Data Review': 'Health Care: Clinica...   \n",
       "84  {'Client Base Retention': 'Marketing and Publi...   \n",
       "85  {'Budgeting': 'Finance: Budget Management;Spec...   \n",
       "86  {'Consultative Sales': 'Sales: Solution Sales ...   \n",
       "87  {'Communication Skills': 'Common Skills', 'Com...   \n",
       "\n",
       "              CanonMinimumDegree CanonRequiredDegrees MinExperience  \\\n",
       "83                       Unknown              Unknown             5   \n",
       "84                       Unknown              Unknown             2   \n",
       "85                    Bachelor's           Bachelor's            13   \n",
       "86                       Unknown              Unknown       Unknown   \n",
       "87  Higher Secondary Certificate              Unknown       Unknown   \n",
       "\n",
       "   ConsolidatedInferredNAICS      BGTOcc CanonJobHours CanonJobType  \\\n",
       "83                    524113  29-2071.96      fulltime    permanent   \n",
       "84                    448310  41-2031.00       Unknown      Unknown   \n",
       "85                    448140  11-1021.91      fulltime    permanent   \n",
       "86                      6233  41-3031.00       Unknown      Unknown   \n",
       "87                    511110  11-2022.00      fulltime    permanent   \n",
       "\n",
       "   CanonYearsOfExperienceCanonLevel CanonYearsOfExperienceLevel  \\\n",
       "83                              1-6                         mid   \n",
       "84                              1-6                         mid   \n",
       "85                               6+                        high   \n",
       "86                          Unknown                     Unknown   \n",
       "87                          Unknown                     Unknown   \n",
       "\n",
       "   ConsolidatedDegreeLevels                  ConsolidatedTitle MinDegreeLevel  \\\n",
       "83                  Unknown     Senior Healthcare Analyst, Sas        Unknown   \n",
       "84                  Unknown                 Sales Professional        Unknown   \n",
       "85                       16  Director, Distribution,Operations             16   \n",
       "86                  Unknown    Financial Services Professional        Unknown   \n",
       "87                    16|12             District Sales Manager             12   \n",
       "\n",
       "                             BGTSubOcc           YearsOfExperience  \\\n",
       "83                  Healthcare Analyst                   5-6 years   \n",
       "84    Retail Sales Associate (General)          minimum of 2 years   \n",
       "85        Retail Operations Supervisor  10+ years|At least 5 years   \n",
       "86   Financial Services Representative                     Unknown   \n",
       "87  Territory / Regional Sales Manager                     Unknown   \n",
       "\n",
       "              EmployerClean                                         clean_text  \n",
       "83       UnitedHealth Group  Sr. Healthcare Analyst - SAS programming skill...  \n",
       "84            Tiffany & Co.  Careers  Iridesse Sales Professional  Req #:  ...  \n",
       "85             Levi Strauss  Job Search Engine - Job Blogs  Friday, October...  \n",
       "86  Brookdale Senior Living  -  Levin Financial Group of Massmutual -  Tamp...  \n",
       "87                USA Today                                                NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ddf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CanonCity                           0.000000\n",
       "CanonState                          0.000000\n",
       "CleanJobTitle                       0.000000\n",
       "JobDate                             0.000000\n",
       "JobID                               0.000000\n",
       "Latitude                            0.000000\n",
       "Longitude                           0.000000\n",
       "CanonPostalCode                     0.000000\n",
       "CanonCounty                         0.000000\n",
       "LMA                                 0.000000\n",
       "MSA                                 0.000000\n",
       "CanonJobTitle                       0.000000\n",
       "ConsolidatedONET                    0.000000\n",
       "InternshipFlag                      0.000000\n",
       "Source                              0.000000\n",
       "CanonSkillClusters                  0.000000\n",
       "CanonSkills                         0.000000\n",
       "CanonMinimumDegree                  0.000000\n",
       "CanonRequiredDegrees                0.000000\n",
       "MinExperience                       0.000000\n",
       "ConsolidatedInferredNAICS           0.000000\n",
       "BGTOcc                              0.000000\n",
       "CanonJobHours                       0.000000\n",
       "CanonJobType                        0.000000\n",
       "CanonYearsOfExperienceCanonLevel    0.000000\n",
       "CanonYearsOfExperienceLevel         0.000000\n",
       "ConsolidatedDegreeLevels            0.000000\n",
       "ConsolidatedTitle                   0.000000\n",
       "MinDegreeLevel                      0.000000\n",
       "BGTSubOcc                           0.000000\n",
       "YearsOfExperience                   0.000000\n",
       "EmployerClean                       0.000000\n",
       "clean_text                          0.007425\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_count = ((ddf.isna().sum() / ddf.index.size) * 100)\n",
    "missing_count_pct = missing_count.compute()\n",
    "missing_count_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_missing = ddf['clean_text'].notnull()\n",
    "ddf = ddf[no_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Measure 1:** The new version Relative usage of up-ward & down-ward terms\n",
    "\n",
    "The two lines below check for first instance of a keyword OR the next OR the next, and so forth. Notice the space in between the pipes (`|`), this is to tell python that, for example, the word `intern` should not be one that is part of `international` but rather its own entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "downward = ddf['clean_text'].str.lower().str.contains(' will supervise | supervising | guiding | mentoring | leading | lead | overseeing | will guide | be in charge of | mentor | coaching | mentoring | coordinating | building teams | build team | guiding | advising | setting performance standard | sets performance standard | resolving conflict | resolves conflict | responsibility for outcomes | responsible for outcomes | directing | appointing | instructing | recruiting | managing | approve | approving | assign | assigning | delegate | delegating | control | controlling | review | reviewing | arbitrate | arbitrating | command | commanding | govern | governing ', regex=True)\n",
    "upward = ddf['clean_text'].str.lower().str.contains(' reports to | report to | reporting to | answers to | answer to | managed by | responds to | respond to | directed by | receives guidance | receive guidance | supervised by | assists | assist | support | supports | supporting | helps | help | helping ', regex=True)\n",
    "\n",
    "ddf0 = ddf.assign(downward=downward, upward=upward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also create two lists with the words above and use them to create the dummies for our dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_words = [' will supervise ', ' supervising ', ' guiding ', ' mentoring ', ' leading ',\n",
    "              ' lead ', ' overseeing ', ' will guide ', ' be in charge of ', ' mentor ', \n",
    "              ' coaching ', ' mentoring ', ' coordinating ', ' building teams ', ' build team ', \n",
    "              ' guiding ', ' advising ', ' setting performance standard ', ' sets performance standard ',\n",
    "              ' resolving conflict ', ' resolves conflict ', ' responsibility for outcomes ', \n",
    "              ' responsible for outcomes ', ' directing ', ' appointing ', ' instructing ',\n",
    "              ' recruiting ', ' managing ', ' approve ', ' approving ', ' assign ', ' assigning ',\n",
    "              ' delegate ', ' delegating ', ' control ', ' controlling ', ' review ', ' reviewing ',\n",
    "              ' arbitrate ', ' arbitrating ', ' command ', ' commanding ', ' govern ', ' governing ']\n",
    "\n",
    "up_words = [' reports to ', ' report to ', ' reporting to ', ' answers to ', ' answer to ', \n",
    "            ' managed by ', ' responds to ', ' respond to ', ' directed by ', ' receives guidance ',\n",
    "            ' receive guidance ', ' supervised by ', ' assists ', ' assist ', ' support ', \n",
    "            ' supports ', ' supporting ', ' helps ', ' help ', ' helping ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indicators(data: pd.DataFrame, column: str, words: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function will check for the existance of a word in a column of a dataframe,\n",
    "    create a dummy variable for it, and add it to back into the dataframe.\n",
    "    \"\"\"\n",
    "    for word in words: # and assign the keyword as a variable and a 1 if the word was found\n",
    "        data[word.strip()] = data[column].str.lower().str.contains(word)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask has a very useful function called `.map_partitions()` that applies a function to each partition of the dask dataframe while treating these partitions as pandas dataframes. We pass in our function and function parameters without parentheses and without calling anything for the data argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1 = ddf0.map_partitions(get_indicators, column='clean_text', words=down_words)\n",
    "ddf2 = ddf1.map_partitions(get_indicators, column='clean_text', words=up_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first clean the list of words above so that we can add them to our dataframe as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_stripped = [w.strip() for w in up_words]\n",
    "down_stripped = [w.strip() for w in down_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then sum up the appearances of both sets of columns to get a sence of how many of these kewords were spotted in a job description. We will then assign the new arrays back into our dask dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_instances = ddf2.loc[:, up_stripped].sum(axis=1)\n",
    "down_instances = ddf2.loc[:, down_stripped].sum(axis=1)\n",
    "ddf3 = ddf2.assign(up_instances=up_instances, down_instances=down_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(word: str, string: str, num_chars: int=60) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    This function will retrieve the set of characters following a keywords that\n",
    "    has been spotted in a piece of string. The defaul number of characters is 60.\n",
    "    \"\"\"\n",
    "    \n",
    "    if word in string:\n",
    "        return string[string.index(word):string.index(word) + num_chars]\n",
    "\n",
    "def get_some_text(data: pd.DataFrame, column: str, list_of_words: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function extends the function get_words by adding the set of characters detected back into\n",
    "    its respective column as a piece of string.\n",
    "    \"\"\"\n",
    "    \n",
    "    for word in list_of_words:\n",
    "        data[word.strip()] = data[column].apply(lambda x: get_words(word, x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now map our functions above to our dataframe partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf4 = ddf3.map_partitions(get_some_text, column='clean_text', list_of_words=down_words)\n",
    "ddf5 = ddf4.map_partitions(get_some_text, column='clean_text', list_of_words=up_words)\n",
    "# ddf5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meassure 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique job titles are there in the firm?\n",
    "1. For each firm-week, firm-year and firm-full-sample, calculate the number of unique (we should have 9 variables for each firm with the number of unique values that either don’t vary within firm, vary within firms each year or vary within firms each week):\n",
    "    - CleanJobTitle\n",
    "    - ConsolidatedJobTitle\n",
    "    - CanonJobTitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this measure we will need to create a couple of additional variables, years and weeks, in order to use them in our `.groupby()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDate = dd.to_datetime(ddf5['JobDate'])\n",
    "ddf6 = ddf5.assign(JobDate=JobDate)\n",
    "weeks = ddf6['JobDate'].dt.week\n",
    "years = ddf6['JobDate'].dt.year\n",
    "ddf7 = ddf6.assign(weeks=weeks, years=years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove duplicate titles from a specific dataset to then use groupby with this deduplicated version. We will then count the jobs within each of the job title variables above and reset the index to get rid of the three dimensional index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_deduplicated = ddf7.drop_duplicates(subset=['CleanJobTitle'])\n",
    "firm_full_sample = ddf_deduplicated.groupby('EmployerClean')[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()\n",
    "firm_year = ddf_deduplicated.groupby(['EmployerClean', 'years'])[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()\n",
    "firm_week = ddf_deduplicated.groupby(['EmployerClean', 'weeks'])[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check the resulf from the above you can run the computations by uncommenting the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 19.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# firm_full_sample, firm_year, firm_week = dask.compute(firm_full_sample, firm_year, firm_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firm_week.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meassure 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managerial intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "For each firm-location-week-occupation, calculate the number of job ads with the managerial job codes available in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "occu_condition = ddf7['BGTOcc'].str.startswith('11')\n",
    "managers_dummy_df = ddf7.assign(managerial_occu=occu_condition)\n",
    "managers_only_df = managers_dummy_df[managers_dummy_df['managerial_occu'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers_group1 = managers_only_df.groupby(['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', 'weeks', 'BGTOcc'])\n",
    "individual_managers = managers_group1[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "For each firm-location-week-alloccups, calculate also the number of job ads with the following job code\n",
    "- Everything starting with ‘11’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers_group2 = managers_only_df.groupby(['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', 'weeks'])\n",
    "all_managers = managers_group2[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "For each firm-location-week, calculate the total number of job ads posted by that firm regardless of the occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_loc_week_group = ddf7.groupby(['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', 'weeks'])\n",
    "firm_loc_week_df = firm_loc_week_group[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check the result from the above cells you can run the computations by uncommenting the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# individual_managers, all_managers, firm_loc_week_df = dask.compute(individual_managers, all_managers, firm_loc_week_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firm_loc_week_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will help you save a csv file with the following characteristics:\n",
    "- choose between 1 or many datasets for the output of your measure\n",
    "- create a new directory for this output, based on the path provided at the beginning of this notebook\n",
    "- add a name for your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_files(new_dir_name, data, new_file_name, pandas_or_dask=True, partitions=None):\n",
    "    \n",
    "    if not os.path.exists(os.path.join(path_out, new_dir_name)):\n",
    "        os.makedirs(os.path.join(path_out, new_dir_name))\n",
    "\n",
    "    if pandas_or_dask == True:\n",
    "        data.to_csv(os.path.join(path_out, new_dir_name) + f'{new_file_name}.csv', index=False)\n",
    "    else:\n",
    "        # the following lines of code will take the last dataset, repartition it,\n",
    "        # and save it to the desired location. Notice the wildcard \"*\" below. That is\n",
    "        # the spot Dask will use to number your files starting from 0\n",
    "        (data\n",
    "         .repartition(npartitions=partitions)\n",
    "         .to_csv(os.path.join(path_out, new_dir_name, f'{new_file_name}*.csv'), index=False)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "save_csv_files(new_dir_name='measure_2/', data=ddf5,                new_file_name='keywords_',           pandas_or_dask=False, partitions=10)\n",
    "save_csv_files(new_dir_name='measure_3/', data=firm_full_sample,    new_file_name='firm_full_sample',    pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_3/', data=firm_year,           new_file_name='firm_year',           pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_3/', data=firm_week,           new_file_name='firm_week',           pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_4/', data=individual_managers, new_file_name='individual_managers', pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_4/', data=all_managers,        new_file_name='all_managers',        pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_4/', data=firm_loc_week_df,    new_file_name='firm_loc_week_df',    pandas_or_dask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
