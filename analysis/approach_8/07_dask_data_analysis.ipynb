{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis at Scale on Filtered Data - Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook will help you create a dataset that addresses the following measures.\n",
    "\n",
    "- **Measure 1:** The new version Relative usage of up-ward & down-ward terms\n",
    "- **Measure 2:** Does the job ad list another job title and tells us who reports to whom?\n",
    "    1. This measure needs to take every keyword above and export the next 7 words in the job ad following it, if any (return NaN otherwise), as a separate column, one for each of the dummies above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to keep in mind before running the code in this notebook.\n",
    "\n",
    "- This notebook assumes you already ran the notebook called \"06_dask_get_companies.ipynb\", which gets you the filtered dataset from the cleaned sample that you will use here. Conversely, you already have access to those datasets\n",
    "- You will be using dask dataframes for distributed computing in your local machine. You can think of these dataframes as lazy pandas (no pun intended)\n",
    "- Depending on how you modify this notebook and decide to use it moving forward, please keep in mind that you might be generating quite a few files at the end of this notebook so make sure to tweak the `save_csv_files`function at the end of the notebook and adjust it to your desire output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re, csv, os\n",
    "import numpy as np\n",
    "from typing import List, Union\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "csv.field_size_limit(10000000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the path where your filtered data files live at and assign it to the `path` variable below. In addition, select a path where you will like the final files to go into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '~/Dropbox/Burning Glass/Data/companies_76k/filtered_data_07/'\n",
    "path_out = '~/Dropbox/Burning Glass/Analysis/approach_8/data_07'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two lists contain the names of the clean variables from the previous steps and the data types we will be using to read them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['JobID', 'CleanJobTitle', 'CanonCity', 'CanonState', 'Source', 'Latitude', \n",
    "             'Longitude', 'CanonJobTitle', 'CanonCounty', 'MSA', 'LMA', 'InternshipFlag',\n",
    "             'ConsolidatedONET', 'CanonSkillClusters', 'CanonSkills', 'CanonMinimumDegree',\n",
    "             'CanonRequiredDegrees', 'MinExperience', 'ConsolidatedInferredNAICS', 'BGTOcc',\n",
    "             'YearsOfExperience', 'CanonJobHours', 'CanonJobType', 'CanonPostalCode', \n",
    "             'CanonYearsOfExperienceCanonLevel', 'CanonYearsOfExperienceLevel', 'ConsolidatedTitle',\n",
    "             'BGTSubOcc', 'ConsolidatedDegreeLevels', 'MinDegreeLevel', 'EmployerClean',\n",
    "             'clean_text', 'JobDate']\n",
    "\n",
    "dtypes={'CanonSkills': np.str, 'Latitude': np.float32, 'JobID': np.str, 'CanonJobTitle': np.str,\n",
    "        'CanonYearsOfExperienceLevel': np.str, 'Longitude': np.float32, 'CanonJobType': np.str, \n",
    "        'CleanJobTitle': np.str, 'ConsolidatedInferredNAICS': np.str, 'CanonRequiredDegrees': np.str,\n",
    "        'YearsOfExperience': np.str, 'CanonCity': np.str, 'CanonCounty': np.str, 'CanonJobHours': np.str,\n",
    "        'CanonState': np.str, 'ConsolidatedONET': np.str, 'MSA': np.str, 'CanonMinimumDegree': np.str,\n",
    "        'ConsolidatedDegreeLevels': np.str, 'BGTSubOcc': np.str, 'ConsolidatedTitle': np.str,\n",
    "        'CanonSkillClusters': np.str, 'Language': np.str, 'JobDate': np.str,\n",
    "        'MinDegreeLevel': np.str, 'LMA': np.str, 'MinExperience': np.str, 'CanonPostalCode': np.str,\n",
    "        'InternshipFlag': np.bool_, 'Source': np.str, 'BGTOcc': np.str, 'CanonYearsOfExperienceCanonLevel': np.str}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cell below onwards, we will begin creating a directed acyclical graph using dask. This means that we will be making barely any computations until the very end of the notebook.\n",
    "\n",
    "The snippet below will help us read in the amount files in the directory specified above. Make sure to place the wildcard `\"*\"` in the appropriate spot, otherwise you will not be able to read in the data. In regular expression term, a wildcard is a placeholder that indicates that any value can be placed at the spot where the wildcard is at. For example, the `\"*\"` in between `da` and `.csv` will allows us to select all of the files that start with `da` and end in `.csv`.\n",
    "\n",
    "Parameters used:\n",
    "\n",
    "- `engine='python'`: the default option uses `C` under the hood and although it is faster, it doesn't give much flexibility regarding data types\n",
    "- `dtype=dtypes`: our list of data types above\n",
    "- `assume_missing=True`: Yes, there might be some edge cases of missing values not taken care of in our previous step\n",
    "- `error_bad_lines=False`: We don't want any bad line in our data so let's allow dask to tell us when they come up\n",
    "- `blocksize=None`: Dask usually tries to read in a small sample of the data and makes inferences as to which data type belongs to a variable. Because in our case some of the job descriptions have quite large amounts of text, dask won't play nicely with our use case and will most likely misinterpret the commas in some of the values in the `JobText` column. To get around this, we will read in every block without making inferences. Luckily, since we created small enough files in the previous step, operations will be very fast.\n",
    "- `usecols=col_names`: our list of columns above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CanonCity</th>\n",
       "      <th>CanonState</th>\n",
       "      <th>CleanJobTitle</th>\n",
       "      <th>JobDate</th>\n",
       "      <th>JobID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>CanonPostalCode</th>\n",
       "      <th>CanonCounty</th>\n",
       "      <th>LMA</th>\n",
       "      <th>MSA</th>\n",
       "      <th>CanonJobTitle</th>\n",
       "      <th>ConsolidatedONET</th>\n",
       "      <th>InternshipFlag</th>\n",
       "      <th>Source</th>\n",
       "      <th>CanonSkillClusters</th>\n",
       "      <th>CanonSkills</th>\n",
       "      <th>CanonMinimumDegree</th>\n",
       "      <th>CanonRequiredDegrees</th>\n",
       "      <th>MinExperience</th>\n",
       "      <th>ConsolidatedInferredNAICS</th>\n",
       "      <th>BGTOcc</th>\n",
       "      <th>CanonJobHours</th>\n",
       "      <th>CanonJobType</th>\n",
       "      <th>CanonYearsOfExperienceCanonLevel</th>\n",
       "      <th>CanonYearsOfExperienceLevel</th>\n",
       "      <th>ConsolidatedDegreeLevels</th>\n",
       "      <th>ConsolidatedTitle</th>\n",
       "      <th>MinDegreeLevel</th>\n",
       "      <th>BGTSubOcc</th>\n",
       "      <th>YearsOfExperience</th>\n",
       "      <th>EmployerClean</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=14</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float32</td>\n",
       "      <td>float32</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from-delayed, 42 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               CanonCity CanonState CleanJobTitle JobDate   JobID Latitude Longitude CanonPostalCode CanonCounty     LMA     MSA CanonJobTitle ConsolidatedONET InternshipFlag  Source CanonSkillClusters CanonSkills CanonMinimumDegree CanonRequiredDegrees MinExperience ConsolidatedInferredNAICS  BGTOcc CanonJobHours CanonJobType CanonYearsOfExperienceCanonLevel CanonYearsOfExperienceLevel ConsolidatedDegreeLevels ConsolidatedTitle MinDegreeLevel BGTSubOcc YearsOfExperience EmployerClean clean_text\n",
       "npartitions=14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "                  object     object        object  object  object  float32   float32          object      object  object  object        object           object           bool  object             object      object             object               object        object                    object  object        object       object                           object                      object                   object            object         object    object            object        object     object\n",
       "                     ...        ...           ...     ...     ...      ...       ...             ...         ...     ...     ...           ...              ...            ...     ...                ...         ...                ...                  ...           ...                       ...     ...           ...          ...                              ...                         ...                      ...               ...            ...       ...               ...           ...        ...\n",
       "...                  ...        ...           ...     ...     ...      ...       ...             ...         ...     ...     ...           ...              ...            ...     ...                ...         ...                ...                  ...           ...                       ...     ...           ...          ...                              ...                         ...                      ...               ...            ...       ...               ...           ...        ...\n",
       "                     ...        ...           ...     ...     ...      ...       ...             ...         ...     ...     ...           ...              ...            ...     ...                ...         ...                ...                  ...           ...                       ...     ...           ...          ...                              ...                         ...                      ...               ...            ...       ...               ...           ...        ...\n",
       "                     ...        ...           ...     ...     ...      ...       ...             ...         ...     ...     ...           ...              ...            ...     ...                ...         ...                ...                  ...           ...                       ...     ...           ...          ...                              ...                         ...                      ...               ...            ...       ...               ...           ...        ...\n",
       "Dask Name: from-delayed, 42 tasks"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = dd.read_csv(os.path.join(path, 'da*.csv'), \n",
    "                 engine='python',\n",
    "                 dtype=dtypes,\n",
    "                 assume_missing=True,\n",
    "                 error_bad_lines=False,\n",
    "                 blocksize=None,\n",
    "                 usecols=col_names,\n",
    "                )\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful when checking the `.head()` or `.tail()` on large groups of data. Depending on how much data you are trying to view, especially if it doesn't fit into memory, this could take anywhere between 2 to 30 minutes or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 s, sys: 432 ms, total: 3.85 s\n",
      "Wall time: 11.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CanonCity</th>\n",
       "      <th>CanonState</th>\n",
       "      <th>CleanJobTitle</th>\n",
       "      <th>JobDate</th>\n",
       "      <th>JobID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>CanonPostalCode</th>\n",
       "      <th>CanonCounty</th>\n",
       "      <th>LMA</th>\n",
       "      <th>MSA</th>\n",
       "      <th>CanonJobTitle</th>\n",
       "      <th>ConsolidatedONET</th>\n",
       "      <th>InternshipFlag</th>\n",
       "      <th>Source</th>\n",
       "      <th>CanonSkillClusters</th>\n",
       "      <th>CanonSkills</th>\n",
       "      <th>CanonMinimumDegree</th>\n",
       "      <th>CanonRequiredDegrees</th>\n",
       "      <th>MinExperience</th>\n",
       "      <th>ConsolidatedInferredNAICS</th>\n",
       "      <th>BGTOcc</th>\n",
       "      <th>CanonJobHours</th>\n",
       "      <th>CanonJobType</th>\n",
       "      <th>CanonYearsOfExperienceCanonLevel</th>\n",
       "      <th>CanonYearsOfExperienceLevel</th>\n",
       "      <th>ConsolidatedDegreeLevels</th>\n",
       "      <th>ConsolidatedTitle</th>\n",
       "      <th>MinDegreeLevel</th>\n",
       "      <th>BGTSubOcc</th>\n",
       "      <th>YearsOfExperience</th>\n",
       "      <th>EmployerClean</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66048</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>Director Of Education And Outreach</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339743939</td>\n",
       "      <td>34.048000</td>\n",
       "      <td>-118.291000</td>\n",
       "      <td>90006</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>DV063108|MT063110</td>\n",
       "      <td>31080: Metropolitan Statistical Area|348: Comb...</td>\n",
       "      <td>Director of Education</td>\n",
       "      <td>11915100</td>\n",
       "      <td>False</td>\n",
       "      <td>Recruiter</td>\n",
       "      <td>Health Care: Mental Health Diseases and Disord...</td>\n",
       "      <td>{\"Alzheimer's Disease knowledge\": 'Health Care...</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>7111</td>\n",
       "      <td>11-9151.00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>18</td>\n",
       "      <td>Director of Education</td>\n",
       "      <td>18</td>\n",
       "      <td>Social / Human Services Manager</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Center Theatre Group</td>\n",
       "      <td>email tiis posting to a friend   please  with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66049</th>\n",
       "      <td>Cypress</td>\n",
       "      <td>CA</td>\n",
       "      <td>Senior Healthcare Analyst - Sas Programming Sk...</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339756230</td>\n",
       "      <td>33.815399</td>\n",
       "      <td>-118.037003</td>\n",
       "      <td>90630</td>\n",
       "      <td>Orange</td>\n",
       "      <td>DV064204|MT063110</td>\n",
       "      <td>31080: Metropolitan Statistical Area|348: Comb...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29207100</td>\n",
       "      <td>False</td>\n",
       "      <td>Company from Job Board</td>\n",
       "      <td>Health Care: Clinical Data Management;Speciali...</td>\n",
       "      <td>{'Clinical Data Review': 'Health Care: Clinica...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>524113</td>\n",
       "      <td>29-2071.96</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>permanent</td>\n",
       "      <td>1-6</td>\n",
       "      <td>mid</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Senior Healthcare Analyst, Sas</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Healthcare Analyst</td>\n",
       "      <td>5-6 years</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>Sr. Healthcare Analyst - SAS programming skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66050</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>CA</td>\n",
       "      <td>Iridesse Sales Professional</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339820992</td>\n",
       "      <td>37.352901</td>\n",
       "      <td>-121.953003</td>\n",
       "      <td>95052</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>MT064194</td>\n",
       "      <td>41940: Metropolitan Statistical Area</td>\n",
       "      <td>Sales Professional</td>\n",
       "      <td>41203100</td>\n",
       "      <td>False</td>\n",
       "      <td>Company from Job Board</td>\n",
       "      <td>Marketing and Public Relations: Customer Relat...</td>\n",
       "      <td>{'Client Base Retention': 'Marketing and Publi...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>448310</td>\n",
       "      <td>41-2031.00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1-6</td>\n",
       "      <td>mid</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Sales Professional</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Retail Sales Associate (General)</td>\n",
       "      <td>minimum of 2 years</td>\n",
       "      <td>Tiffany &amp; Co.</td>\n",
       "      <td>Careers  Iridesse Sales Professional  Req #:  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66051</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>Director, Distribution Center Operations</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339820871</td>\n",
       "      <td>37.779800</td>\n",
       "      <td>-122.417000</td>\n",
       "      <td>94175</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>DV064188|MT064186</td>\n",
       "      <td>41860: Metropolitan Statistical Area|488: Comb...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11102100</td>\n",
       "      <td>False</td>\n",
       "      <td>Company from Job Board</td>\n",
       "      <td>Finance: Budget Management;Specialized Skills|...</td>\n",
       "      <td>{'Budgeting': 'Finance: Budget Management;Spec...</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>13</td>\n",
       "      <td>448140</td>\n",
       "      <td>11-1021.91</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>permanent</td>\n",
       "      <td>6+</td>\n",
       "      <td>high</td>\n",
       "      <td>16</td>\n",
       "      <td>Director, Distribution,Operations</td>\n",
       "      <td>16</td>\n",
       "      <td>Retail Operations Supervisor</td>\n",
       "      <td>10+ years|At least 5 years</td>\n",
       "      <td>Levi Strauss</td>\n",
       "      <td>Job Search Engine - Job Blogs  Friday, October...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66052</th>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>Financial Services Professional</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>360306555</td>\n",
       "      <td>25.794901</td>\n",
       "      <td>-80.127800</td>\n",
       "      <td>33159</td>\n",
       "      <td>Miami-Dade</td>\n",
       "      <td>DV123312|MT123310</td>\n",
       "      <td>33100: Metropolitan Statistical Area|370: Comb...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>41303102</td>\n",
       "      <td>False</td>\n",
       "      <td>Job Board</td>\n",
       "      <td>Sales: Solution Sales Engineering;Specialized ...</td>\n",
       "      <td>{'Consultative Sales': 'Sales: Solution Sales ...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>6233</td>\n",
       "      <td>41-3031.00</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Financial Services Professional</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Financial Services Representative</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Brookdale Senior Living</td>\n",
       "      <td>-  Levin Financial Group of Massmutual -  Tamp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CanonCity CanonState  \\\n",
       "66048    Los Angeles         CA   \n",
       "66049        Cypress         CA   \n",
       "66050    Santa Clara         CA   \n",
       "66051  San Francisco         CA   \n",
       "66052          Miami         FL   \n",
       "\n",
       "                                           CleanJobTitle     JobDate  \\\n",
       "66048                 Director Of Education And Outreach  2007-12-31   \n",
       "66049  Senior Healthcare Analyst - Sas Programming Sk...  2007-12-31   \n",
       "66050                        Iridesse Sales Professional  2007-12-31   \n",
       "66051           Director, Distribution Center Operations  2007-12-31   \n",
       "66052                    Financial Services Professional  2007-12-31   \n",
       "\n",
       "           JobID   Latitude   Longitude CanonPostalCode    CanonCounty  \\\n",
       "66048  339743939  34.048000 -118.291000           90006    Los Angeles   \n",
       "66049  339756230  33.815399 -118.037003           90630         Orange   \n",
       "66050  339820992  37.352901 -121.953003           95052    Santa Clara   \n",
       "66051  339820871  37.779800 -122.417000           94175  San Francisco   \n",
       "66052  360306555  25.794901  -80.127800           33159     Miami-Dade   \n",
       "\n",
       "                     LMA                                                MSA  \\\n",
       "66048  DV063108|MT063110  31080: Metropolitan Statistical Area|348: Comb...   \n",
       "66049  DV064204|MT063110  31080: Metropolitan Statistical Area|348: Comb...   \n",
       "66050           MT064194               41940: Metropolitan Statistical Area   \n",
       "66051  DV064188|MT064186  41860: Metropolitan Statistical Area|488: Comb...   \n",
       "66052  DV123312|MT123310  33100: Metropolitan Statistical Area|370: Comb...   \n",
       "\n",
       "               CanonJobTitle ConsolidatedONET  InternshipFlag  \\\n",
       "66048  Director of Education         11915100           False   \n",
       "66049                Unknown         29207100           False   \n",
       "66050     Sales Professional         41203100           False   \n",
       "66051                Unknown         11102100           False   \n",
       "66052                Unknown         41303102           False   \n",
       "\n",
       "                       Source  \\\n",
       "66048               Recruiter   \n",
       "66049  Company from Job Board   \n",
       "66050  Company from Job Board   \n",
       "66051  Company from Job Board   \n",
       "66052               Job Board   \n",
       "\n",
       "                                      CanonSkillClusters  \\\n",
       "66048  Health Care: Mental Health Diseases and Disord...   \n",
       "66049  Health Care: Clinical Data Management;Speciali...   \n",
       "66050  Marketing and Public Relations: Customer Relat...   \n",
       "66051  Finance: Budget Management;Specialized Skills|...   \n",
       "66052  Sales: Solution Sales Engineering;Specialized ...   \n",
       "\n",
       "                                             CanonSkills CanonMinimumDegree  \\\n",
       "66048  {\"Alzheimer's Disease knowledge\": 'Health Care...           Master's   \n",
       "66049  {'Clinical Data Review': 'Health Care: Clinica...            Unknown   \n",
       "66050  {'Client Base Retention': 'Marketing and Publi...            Unknown   \n",
       "66051  {'Budgeting': 'Finance: Budget Management;Spec...         Bachelor's   \n",
       "66052  {'Consultative Sales': 'Sales: Solution Sales ...            Unknown   \n",
       "\n",
       "      CanonRequiredDegrees MinExperience ConsolidatedInferredNAICS  \\\n",
       "66048              Unknown       Unknown                      7111   \n",
       "66049              Unknown             5                    524113   \n",
       "66050              Unknown             2                    448310   \n",
       "66051           Bachelor's            13                    448140   \n",
       "66052              Unknown       Unknown                      6233   \n",
       "\n",
       "           BGTOcc CanonJobHours CanonJobType CanonYearsOfExperienceCanonLevel  \\\n",
       "66048  11-9151.00       Unknown      Unknown                          Unknown   \n",
       "66049  29-2071.96      fulltime    permanent                              1-6   \n",
       "66050  41-2031.00       Unknown      Unknown                              1-6   \n",
       "66051  11-1021.91      fulltime    permanent                               6+   \n",
       "66052  41-3031.00       Unknown      Unknown                          Unknown   \n",
       "\n",
       "      CanonYearsOfExperienceLevel ConsolidatedDegreeLevels  \\\n",
       "66048                     Unknown                       18   \n",
       "66049                         mid                  Unknown   \n",
       "66050                         mid                  Unknown   \n",
       "66051                        high                       16   \n",
       "66052                     Unknown                  Unknown   \n",
       "\n",
       "                       ConsolidatedTitle MinDegreeLevel  \\\n",
       "66048              Director of Education             18   \n",
       "66049     Senior Healthcare Analyst, Sas        Unknown   \n",
       "66050                 Sales Professional        Unknown   \n",
       "66051  Director, Distribution,Operations             16   \n",
       "66052    Financial Services Professional        Unknown   \n",
       "\n",
       "                               BGTSubOcc           YearsOfExperience  \\\n",
       "66048    Social / Human Services Manager                     Unknown   \n",
       "66049                 Healthcare Analyst                   5-6 years   \n",
       "66050   Retail Sales Associate (General)          minimum of 2 years   \n",
       "66051       Retail Operations Supervisor  10+ years|At least 5 years   \n",
       "66052  Financial Services Representative                     Unknown   \n",
       "\n",
       "                 EmployerClean  \\\n",
       "66048     Center Theatre Group   \n",
       "66049       UnitedHealth Group   \n",
       "66050            Tiffany & Co.   \n",
       "66051             Levi Strauss   \n",
       "66052  Brookdale Senior Living   \n",
       "\n",
       "                                              clean_text  \n",
       "66048  email tiis posting to a friend   please  with ...  \n",
       "66049  Sr. Healthcare Analyst - SAS programming skill...  \n",
       "66050  Careers  Iridesse Sales Professional  Req #:  ...  \n",
       "66051  Job Search Engine - Job Blogs  Friday, October...  \n",
       "66052  -  Levin Financial Group of Massmutual -  Tamp...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ddf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Measure 1:** The new version Relative usage of up-ward & down-ward terms\n",
    "\n",
    "The lines below check for first instance of a keyword OR the next OR the next, and so forth. Notice the space in between the pipes (`|`), this tells python that, for example, the word `intern` should not be part of `international` but rather its own entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "downward = ddf['clean_text'].str.lower().str.contains(' will supervise | supervising | guiding | mentoring | leading | lead | overseeing | will guide | be in charge of | mentor | coaching | mentoring | coordinating | building teams | build team | guiding | advising | setting performance standard | sets performance standard | resolving conflict | resolves conflict | responsibility for outcomes | responsible for outcomes | directing | appointing | instructing | recruiting | managing | approve | approving | assign | assigning | delegate | delegating | control | controlling | review | reviewing | arbitrate | arbitrating | command | commanding | govern | governing ', regex=True)\n",
    "upward = ddf['clean_text'].str.lower().str.contains(' reports to | report to | reporting to | answers to | answer to | managed by | responds to | respond to | directed by | receives guidance | receive guidance | supervised by | assists | assist | support | supports | supporting | helps | help | helping ', regex=True)\n",
    "\n",
    "ddf0 = ddf.assign(downward=downward, upward=upward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also create two lists with the words above and use them to create the dummies for our dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "down_words = [' will supervise ', ' supervising ', ' guiding ', ' mentoring ', ' leading ',\n",
    "              ' lead ', ' overseeing ', ' will guide ', ' be in charge of ', ' mentor ', \n",
    "              ' coaching ', ' mentoring ', ' coordinating ', ' building teams ', ' build team ', \n",
    "              ' guiding ', ' advising ', ' setting performance standard ', ' sets performance standard ',\n",
    "              ' resolving conflict ', ' resolves conflict ', ' responsibility for outcomes ', \n",
    "              ' responsible for outcomes ', ' directing ', ' appointing ', ' instructing ',\n",
    "              ' recruiting ', ' managing ', ' approve ', ' approving ', ' assign ', ' assigning ',\n",
    "              ' delegate ', ' delegating ', ' control ', ' controlling ', ' review ', ' reviewing ',\n",
    "              ' arbitrate ', ' arbitrating ', ' command ', ' commanding ', ' govern ', ' governing ']\n",
    "\n",
    "up_words = [' reports to ', ' report to ', ' reporting to ', ' answers to ', ' answer to ', \n",
    "            ' managed by ', ' responds to ', ' respond to ', ' directed by ', ' receives guidance ',\n",
    "            ' receive guidance ', ' supervised by ', ' assists ', ' assist ', ' support ', \n",
    "            ' supports ', ' supporting ', ' helps ', ' help ', ' helping ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some functions, I declare the data type explicitly to make it easier for any user to understand what goes in and what comes out of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indicators(data: pd.DataFrame, column: str, words: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function will check for the existance of a word in a column of a dataframe,\n",
    "    create a dummy variable for it, and add it to back into the dataframe.\n",
    "    \"\"\"\n",
    "    for word in words: # and assign the keyword as a variable and a 1 if the word was found\n",
    "        data[word.strip()] = data[column].str.lower().str.contains(word)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask has a very useful function called `.map_partitions()` that applies a function to each partition of the dask dataframe while treating these partitions as pandas dataframes. We pass in our function and function parameters without parentheses and without calling anything for the data argument since that will be the job of the partitions (e.g. small pandas dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf1 = ddf0.map_partitions(get_indicators, column='clean_text', words=down_words)\n",
    "ddf2 = ddf1.map_partitions(get_indicators, column='clean_text', words=up_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first clean the list of words above so that we can add them to our dask dataframe as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_stripped = [w.strip() for w in up_words]\n",
    "down_stripped = [w.strip() for w in down_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then sum up the appearances of both sets of columns to get a sence of how many of these kewords were spotted in a job description. We will then assign the new arrays back into our dask dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_instances = ddf2.loc[:, up_stripped].sum(axis=1)\n",
    "down_instances = ddf2.loc[:, down_stripped].sum(axis=1)\n",
    "\n",
    "ddf3 = ddf2.assign(up_instances=up_instances, down_instances=down_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create two functions that will help us extract the words that follow our keywords. Notice that the `num_char` parameter below will extract by default the 60 characters following our keyword. You can change it to different values to get more or less words following the keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(word: str, string: str, num_chars: int = 60) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    This function will retrieve the set of characters following a keywords that\n",
    "    has been spotted in a piece of string. The defaul number of characters is 60.\n",
    "    \"\"\"\n",
    "    \n",
    "    if word in string:\n",
    "        return string[string.index(word):string.index(word) + num_chars]\n",
    "\n",
    "def get_some_text(data: pd.DataFrame, column: str, list_of_words: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function extends the function get_words by adding the set of characters detected back into\n",
    "    its respective column as a piece of string.\n",
    "    \"\"\"\n",
    "    \n",
    "    for word in list_of_words:\n",
    "        data[word.strip()] = data[column].apply(lambda x: get_words(word, x))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now map our functions above to our dataframe partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf4 = ddf3.map_partitions(get_some_text, column='clean_text', list_of_words=down_words)\n",
    "ddf5 = ddf4.map_partitions(get_some_text, column='clean_text', list_of_words=up_words)\n",
    "# ddf5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all Files\n",
    "\n",
    "The following function will help you save a csv file with the following characteristics:\n",
    "- choose between 1 or many datasets for the output of your measure\n",
    "- create a new directory for this output, based on the `path_out` variable provided at the beginning of this notebook\n",
    "- add a name for your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_files(new_dir_name, data, new_file_name, pandas_or_dask=True, partitions=None):\n",
    "    \n",
    "    if not os.path.exists(os.path.join(path_out, new_dir_name)):\n",
    "        os.makedirs(os.path.join(path_out, new_dir_name))\n",
    "\n",
    "    if pandas_or_dask == True:\n",
    "        data = data.compute()\n",
    "        data.to_csv(os.path.join(path_out, new_dir_name, f'{new_file_name}.csv'), index=False)\n",
    "    else:\n",
    "        # the following lines of code will take the last dataset, repartition it,\n",
    "        # and save it to the desired location. Notice the wildcard \"*\" below. That is\n",
    "        # the spot Dask will use to number your files starting from 0\n",
    "        (data\n",
    "         .repartition(npartitions=partitions)\n",
    "         .to_csv(os.path.join(path_out, new_dir_name, f'{new_file_name}*.csv'), index=False)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 46s, sys: 12min 23s, total: 26min 9s\n",
      "Wall time: 42min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "save_csv_files(new_dir_name='measure_2/', data=ddf5, new_file_name='keywords_', pandas_or_dask=False, partitions=25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
