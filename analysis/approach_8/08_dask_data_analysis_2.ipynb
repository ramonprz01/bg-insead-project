{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help you get answers for the following measures.\n",
    "\n",
    "- **Measure 3:** How many unique job titles are there in the firm?\n",
    "    1. For each firm-week, firm-year and firm-full-sample, calculate the number of unique (we should have 9 variables for each firm with the number of unique values that either don’t vary within firm, vary within firms each year or vary within firms each week):\n",
    "        - CleanJobTitle\n",
    "        - ConsolidatedJobTitle\n",
    "        - CanonJobTitle\n",
    "- **Measure 4:** Managerial intensity?\n",
    "    1. For each firm-location-week-occupationbelow, calculate the number of job ads with the following job codes:\n",
    "    2. For each firm-location-week-alloccups, calculate also the number of job ads with the following job code:\n",
    "        - Everything starting with ‘11’\n",
    "    3. For each firm-location-week, calculate also the total number of job ads posted by that firm regardless of the occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, dask.dataframe as dd, dask.array as da\n",
    "from dask.diagnostics import ProgressBar\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re, csv, os\n",
    "import numpy as np\n",
    "from dask import delayed, persist\n",
    "from dask.distributed import Client\n",
    "from glob import glob\n",
    "from typing import List, Union\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "csv.field_size_limit(10000000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ramonperez/Dropbox/Burning Glass/Data/companies_76k/filtered_data_14/'\n",
    "path_out = '/Users/ramonperez/Dropbox/Burning Glass/Analysis/approach_8/data_14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['JobID', 'CleanJobTitle', 'CanonCity', 'CanonState', 'CanonJobTitle', 'CanonCounty', \n",
    "             'BGTOcc', 'CanonPostalCode', 'ConsolidatedTitle', 'EmployerClean', 'JobDate']\n",
    "\n",
    "dtypes={'CanonSkills': np.str, 'Latitude': np.float32, 'JobID': np.str, 'CanonJobTitle': np.str,\n",
    "        'CanonYearsOfExperienceLevel': np.str, 'Longitude': np.float32, 'CanonJobType': np.str, \n",
    "        'CleanJobTitle': np.str, 'ConsolidatedInferredNAICS': np.str, 'CanonRequiredDegrees': np.str,\n",
    "        'YearsOfExperience': np.str, 'CanonCity': np.str, 'CanonCounty': np.str, 'CanonJobHours': np.str,\n",
    "        'CanonState': np.str, 'ConsolidatedONET': np.str, 'MSA': np.str, 'CanonMinimumDegree': np.str,\n",
    "        'ConsolidatedDegreeLevels': np.str, 'BGTSubOcc': np.str, 'ConsolidatedTitle': np.str,\n",
    "        'CanonSkillClusters': np.str, 'Language': np.str, 'JobDate': np.str,\n",
    "        'MinDegreeLevel': np.str, 'LMA': np.str, 'MinExperience': np.str, 'CanonPostalCode': np.str,\n",
    "        'InternshipFlag': np.bool_, 'Source': np.str, 'BGTOcc': np.str, 'CanonYearsOfExperienceCanonLevel': np.str}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 59: unexpected end of data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CanonCity</th>\n",
       "      <th>CanonState</th>\n",
       "      <th>CleanJobTitle</th>\n",
       "      <th>JobDate</th>\n",
       "      <th>JobID</th>\n",
       "      <th>CanonPostalCode</th>\n",
       "      <th>CanonCounty</th>\n",
       "      <th>CanonJobTitle</th>\n",
       "      <th>BGTOcc</th>\n",
       "      <th>ConsolidatedTitle</th>\n",
       "      <th>EmployerClean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=50</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from-delayed, 150 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               CanonCity CanonState CleanJobTitle JobDate   JobID CanonPostalCode CanonCounty CanonJobTitle  BGTOcc ConsolidatedTitle EmployerClean\n",
       "npartitions=50                                                                                                                                     \n",
       "                  object     object        object  object  object          object      object        object  object            object        object\n",
       "                     ...        ...           ...     ...     ...             ...         ...           ...     ...               ...           ...\n",
       "...                  ...        ...           ...     ...     ...             ...         ...           ...     ...               ...           ...\n",
       "                     ...        ...           ...     ...     ...             ...         ...           ...     ...               ...           ...\n",
       "                     ...        ...           ...     ...     ...             ...         ...           ...     ...               ...           ...\n",
       "Dask Name: from-delayed, 150 tasks"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = dd.read_csv(os.path.join(path, 'da*.csv'), \n",
    "                 engine='python',\n",
    "                 dtype=dtypes,\n",
    "                 assume_missing=True,\n",
    "                 error_bad_lines=False,\n",
    "                 blocksize=None,\n",
    "                 usecols=col_names,\n",
    "                )\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meassure 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique job titles are there in the firm?\n",
    "1. For each firm-week, firm-year and firm-full-sample, calculate the number of unique (we should have 9 variables for each firm with the number of unique values that either don’t vary within firm, vary within firms each year or vary within firms each week):\n",
    "    - CleanJobTitle\n",
    "    - ConsolidatedJobTitle\n",
    "    - CanonJobTitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this measure we will need to create a couple of additional variables, years and weeks, in order to use them in our `.groupby()` call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You have changed ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDate = dd.to_datetime(ddf['JobDate'])\n",
    "ddf6 = ddf.assign(JobDate=JobDate)\n",
    "weeks = ddf6['JobDate'].dt.week\n",
    "years = ddf6['JobDate'].dt.year\n",
    "ddf7 = ddf6.assign(weeks=weeks, years=years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove duplicate titles from a specific dataset to then use groupby with this deduplicated version. We will then count the jobs within each of the job title variables above and reset the index to get rid of the three dimensional index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_deduplicated = ddf7.drop_duplicates(subset=['CleanJobTitle'])\n",
    "ddf_deduplicated2 = ddf_deduplicated[['EmployerClean', 'CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle', 'years', 'weeks']].replace('Unknown', np.nan)\n",
    "firm_full_sample = ddf_deduplicated2.groupby('EmployerClean')[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()\n",
    "firm_year = ddf_deduplicated2.groupby(['EmployerClean', 'years'])[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()\n",
    "firm_week = ddf_deduplicated2.groupby(['EmployerClean', 'weeks'])[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check the resulf from the above you can run the computations by uncommenting the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 3 µs, total: 7 µs\n",
      "Wall time: 27.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# firm_full_sample, firm_year, firm_week = dask.compute(firm_full_sample, firm_year, firm_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firm_week.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meassure 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managerial intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1\n",
    "\n",
    "For each firm-location-week-occupation, calculate the number of job ads with the managerial job codes available in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "occu_condition = ddf7['BGTOcc'].str.startswith('11')\n",
    "managers_dummy_df = ddf7.assign(managerial_occu=occu_condition)\n",
    "managers_only_df = managers_dummy_df[managers_dummy_df['managerial_occu'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers_only_df1 = managers_only_df[['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', \n",
    "                                      'weeks', 'BGTOcc', 'CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].replace('Unknown', np.nan)\n",
    "managers_group1 = managers_only_df1.groupby(['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', 'weeks', 'BGTOcc'])\n",
    "individual_managers = managers_group1[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "For each firm-location-week-alloccups, calculate also the number of job ads with the following job code\n",
    "- Everything starting with ‘11’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers_group2 = managers_only_df1.groupby(['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', 'weeks'])\n",
    "all_managers = managers_group2[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "For each firm-location-week, calculate the total number of job ads posted by that firm regardless of the occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf8 = ddf7[['EmployerClean', 'CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle', 'years', 'weeks', 'CanonState', 'CanonCounty', 'CanonPostalCode']].replace('Unknown', np.nan)\n",
    "firm_loc_week_group = ddf8.groupby(['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', 'weeks'])\n",
    "firm_loc_week_df = firm_loc_week_group[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check the result from the above cells you can run the computations by uncommenting the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 4.05 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# individual_managers, all_managers, firm_loc_week_df = dask.compute(individual_managers, all_managers, firm_loc_week_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firm_loc_week_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will help you save a csv file with the following characteristics:\n",
    "- choose between 1 or many datasets for the output of your measure\n",
    "- create a new directory for this output, based on the path provided at the beginning of this notebook\n",
    "- add a name for your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_files(new_dir_name, data, new_file_name, pandas_or_dask=True, partitions=None):\n",
    "    \n",
    "    if not os.path.exists(os.path.join(path_out, new_dir_name)):\n",
    "        os.makedirs(os.path.join(path_out, new_dir_name))\n",
    "\n",
    "    if pandas_or_dask == True:\n",
    "        data = data.compute()\n",
    "        data.to_csv(os.path.join(path_out, new_dir_name, f'{new_file_name}.csv'), index=False)\n",
    "    else:\n",
    "        # the following lines of code will take the last dataset, repartition it,\n",
    "        # and save it to the desired location. Notice the wildcard \"*\" below. That is\n",
    "        # the spot Dask will use to number your files starting from 0\n",
    "        (data\n",
    "         .repartition(npartitions=partitions)\n",
    "         .to_csv(os.path.join(path_out, new_dir_name, f'{new_file_name}*.csv'), index=False)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 10s, sys: 5min 55s, total: 22min 6s\n",
      "Wall time: 25min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "save_csv_files(new_dir_name='measure_3/', data=firm_full_sample,    new_file_name='firm_full_sample',    pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_3/', data=firm_year,           new_file_name='firm_year',           pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_3/', data=firm_week,           new_file_name='firm_week',           pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_4/', data=individual_managers, new_file_name='individual_managers', pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_4/', data=all_managers,        new_file_name='all_managers',        pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_4/', data=firm_loc_week_df,    new_file_name='firm_loc_week_df',    pandas_or_dask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
