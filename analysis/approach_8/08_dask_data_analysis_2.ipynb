{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis at Scale on Filtered Data - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in this notebook will help you create a dataset that addresses the following measures.\n",
    "\n",
    "- **Measure 3:** How many unique job titles are there in the firm?\n",
    "    1. For each firm-week, firm-year and firm-full-sample, calculate the number of unique (we should have 9 variables for each firm with the number of unique values that either don’t vary within firm, vary within firms each year or vary within firms each week):\n",
    "        - CleanJobTitle\n",
    "        - ConsolidatedJobTitle\n",
    "        - CanonJobTitle\n",
    "- **Measure 4:** Managerial intensity?\n",
    "    1. For each firm-location-week-occupationbelow, calculate the number of job ads with the following job codes:\n",
    "    2. For each firm-location-week-alloccups, calculate also the number of job ads with the following job code:\n",
    "        - Everything starting with ‘11’\n",
    "    3. For each firm-location-week, calculate also the total number of job ads posted by that firm regardless of the occupation\n",
    "\n",
    "### Things to keep in mind before running the code in this notebook.\n",
    "\n",
    "- This notebook assumes you already ran the notebook called \"06_dask_get_companies.ipynb\", which gets you the filtered dataset from the cleaned sample that you will use here. Conversely, you already have access to those datasets\n",
    "- You will be using dask dataframes for distributed computing in your local machine. You can think of these dataframes as lazy pandas (no pun intended)\n",
    "- Depending on how you modify this notebook and decide to use it moving forward, please keep in mind that you might be generating quite a few files at the end of this notebook so make sure to tweak the `save_csv_files`function at the end of the notebook and adjust it to your desire output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask, dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re, csv, os\n",
    "import numpy as np\n",
    "from typing import List, Union\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "csv.field_size_limit(10000000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the path where your filtered data files live at and assign it to the `path` variable below. In addition, select a path where you will like the final files to go into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '~/Dropbox/Burning Glass/Data/companies_76k/filtered_data_07/'\n",
    "path_out = '~/Dropbox/Burning Glass/Analysis/approach_8/data_07'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two lists contain the names of the clean variables from the previous steps and the data types we will be using to read them in. Because we don't need all the variables for the following 2 measures, we will limit our selection to only what is neede and to speed up process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['JobID', 'CleanJobTitle', 'CanonCity', 'CanonState', 'CanonJobTitle', 'CanonCounty', \n",
    "             'BGTOcc', 'CanonPostalCode', 'ConsolidatedTitle', 'EmployerClean', 'JobDate']\n",
    "\n",
    "dtypes={'JobID': np.str, 'CanonJobTitle': np.str, 'EmployerClean': np.str,\n",
    "        'CleanJobTitle': np.str, 'CanonCity': np.str, 'CanonCounty': np.str,\n",
    "        'CanonState': np.str, 'ConsolidatedTitle': np.str, 'BGTOcc': np.str,\n",
    "        'JobDate': np.str, 'CanonPostalCode': np.str}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the cell below onwards, we will begin creating a directed acyclical graph using dask. This means that we will be making barely any computations until the very end of the notebook.\n",
    "\n",
    "The snippet below will help us read in the amount files in the directory specified above. Make sure to place the wildcard `\"*\"` in the appropriate spot, otherwise you will not be able to read in the data. In regular expression term, a wildcard is a placeholder that indicates that any value can be placed at the spot where the wildcard is at. For example, the `\"*\"` in between `da` and `.csv` will allows us to select all of the files that start with `da` and end in `.csv`.\n",
    "\n",
    "Parameters used:\n",
    "\n",
    "- `engine='python'`: the default option uses `C` under the hood and although it is faster, it doesn't give much flexibility regarding data types\n",
    "- `dtype=dtypes`: our list of data types above\n",
    "- `assume_missing=True`: Yes, there might be some edge cases of missing values not taken care of in our previous step\n",
    "- `error_bad_lines=False`: We don't want any bad line in our data so let's allow dask to tell us when they come up\n",
    "- `blocksize=None`: Dask usually tries to read in a small sample of the data and makes inferences as to which data type belongs to a variable. Because in our case some of the job descriptions have quite large amounts of text, dask won't play nicely with our use case and will most likely misinterpret the commas in some of the values in the `JobText` column. To get around this, we will read in every block without making inferences. Luckily, since we created small enough files in the previous step, operations will be very fast.\n",
    "- `usecols=col_names`: our list of columns above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CanonCity</th>\n",
       "      <th>CanonState</th>\n",
       "      <th>CleanJobTitle</th>\n",
       "      <th>JobDate</th>\n",
       "      <th>JobID</th>\n",
       "      <th>CanonPostalCode</th>\n",
       "      <th>CanonCounty</th>\n",
       "      <th>CanonJobTitle</th>\n",
       "      <th>BGTOcc</th>\n",
       "      <th>ConsolidatedTitle</th>\n",
       "      <th>EmployerClean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=14</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from-delayed, 42 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               CanonCity CanonState CleanJobTitle JobDate   JobID CanonPostalCode CanonCounty CanonJobTitle  BGTOcc ConsolidatedTitle EmployerClean\n",
       "npartitions=14                                                                                                                                     \n",
       "                  object     object        object  object  object          object      object        object  object            object        object\n",
       "                     ...        ...           ...     ...     ...             ...         ...           ...     ...               ...           ...\n",
       "...                  ...        ...           ...     ...     ...             ...         ...           ...     ...               ...           ...\n",
       "                     ...        ...           ...     ...     ...             ...         ...           ...     ...               ...           ...\n",
       "                     ...        ...           ...     ...     ...             ...         ...           ...     ...               ...           ...\n",
       "Dask Name: from-delayed, 42 tasks"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = dd.read_csv(os.path.join(path, 'da*.csv'), \n",
    "                 engine='python',\n",
    "                 dtype=dtypes,\n",
    "                 assume_missing=True,\n",
    "                 error_bad_lines=False,\n",
    "                 blocksize=None,\n",
    "                 usecols=col_names,\n",
    "                )\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful when checking the `.head()` or `.tail()` on large groups of data. Depending on how much data you are trying to view, especially if it doesn't fit into memory, this could take anywhere between 2 to 30 minutes or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.18 s, sys: 290 ms, total: 3.47 s\n",
      "Wall time: 3.54 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CanonCity</th>\n",
       "      <th>CanonState</th>\n",
       "      <th>CleanJobTitle</th>\n",
       "      <th>JobDate</th>\n",
       "      <th>JobID</th>\n",
       "      <th>CanonPostalCode</th>\n",
       "      <th>CanonCounty</th>\n",
       "      <th>CanonJobTitle</th>\n",
       "      <th>BGTOcc</th>\n",
       "      <th>ConsolidatedTitle</th>\n",
       "      <th>EmployerClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66048</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>Director Of Education And Outreach</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339743939</td>\n",
       "      <td>90006</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Director of Education</td>\n",
       "      <td>11-9151.00</td>\n",
       "      <td>Director of Education</td>\n",
       "      <td>Center Theatre Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66049</th>\n",
       "      <td>Cypress</td>\n",
       "      <td>CA</td>\n",
       "      <td>Senior Healthcare Analyst - Sas Programming Sk...</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339756230</td>\n",
       "      <td>90630</td>\n",
       "      <td>Orange</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>29-2071.96</td>\n",
       "      <td>Senior Healthcare Analyst, Sas</td>\n",
       "      <td>UnitedHealth Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66050</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>CA</td>\n",
       "      <td>Iridesse Sales Professional</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339820992</td>\n",
       "      <td>95052</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>Sales Professional</td>\n",
       "      <td>41-2031.00</td>\n",
       "      <td>Sales Professional</td>\n",
       "      <td>Tiffany &amp; Co.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66051</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>Director, Distribution Center Operations</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>339820871</td>\n",
       "      <td>94175</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>11-1021.91</td>\n",
       "      <td>Director, Distribution,Operations</td>\n",
       "      <td>Levi Strauss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66052</th>\n",
       "      <td>Miami</td>\n",
       "      <td>FL</td>\n",
       "      <td>Financial Services Professional</td>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>360306555</td>\n",
       "      <td>33159</td>\n",
       "      <td>Miami-Dade</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>41-3031.00</td>\n",
       "      <td>Financial Services Professional</td>\n",
       "      <td>Brookdale Senior Living</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CanonCity CanonState  \\\n",
       "66048    Los Angeles         CA   \n",
       "66049        Cypress         CA   \n",
       "66050    Santa Clara         CA   \n",
       "66051  San Francisco         CA   \n",
       "66052          Miami         FL   \n",
       "\n",
       "                                           CleanJobTitle     JobDate  \\\n",
       "66048                 Director Of Education And Outreach  2007-12-31   \n",
       "66049  Senior Healthcare Analyst - Sas Programming Sk...  2007-12-31   \n",
       "66050                        Iridesse Sales Professional  2007-12-31   \n",
       "66051           Director, Distribution Center Operations  2007-12-31   \n",
       "66052                    Financial Services Professional  2007-12-31   \n",
       "\n",
       "           JobID CanonPostalCode    CanonCounty          CanonJobTitle  \\\n",
       "66048  339743939           90006    Los Angeles  Director of Education   \n",
       "66049  339756230           90630         Orange                Unknown   \n",
       "66050  339820992           95052    Santa Clara     Sales Professional   \n",
       "66051  339820871           94175  San Francisco                Unknown   \n",
       "66052  360306555           33159     Miami-Dade                Unknown   \n",
       "\n",
       "           BGTOcc                  ConsolidatedTitle            EmployerClean  \n",
       "66048  11-9151.00              Director of Education     Center Theatre Group  \n",
       "66049  29-2071.96     Senior Healthcare Analyst, Sas       UnitedHealth Group  \n",
       "66050  41-2031.00                 Sales Professional            Tiffany & Co.  \n",
       "66051  11-1021.91  Director, Distribution,Operations             Levi Strauss  \n",
       "66052  41-3031.00    Financial Services Professional  Brookdale Senior Living  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ddf.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meassure 3\n",
    "\n",
    "How many unique job titles are there in the firm?\n",
    "1. For each firm-week, firm-year and firm-full-sample, calculate the number of unique (we should have 9 variables for each firm with the number of unique values that either don’t vary within firm, vary within firms each year or vary within firms each week):\n",
    "    - CleanJobTitle\n",
    "    - ConsolidatedJobTitle\n",
    "    - CanonJobTitle\n",
    "\n",
    "For this measure we will need to create a couple of additional variables, `years` and `weeks`, in order to use them in our `.groupby()` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "JobDate = dd.to_datetime(ddf['JobDate'])\n",
    "ddf1 = ddf.assign(JobDate=JobDate)\n",
    "weeks = ddf1['JobDate'].dt.week\n",
    "years = ddf1['JobDate'].dt.year\n",
    "ddf2 = ddf1.assign(weeks=weeks, years=years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will remove duplicate titles from a specific dataset to then use groupby with this deduplicated version. We will then count the jobs within each of the job title variables above and reset the index to get rid of the three-dimensional dataframes. Also, in the cell below we will remove the `\"Unkown\"` placeholder for missing values with `np.nan` so that we don't count these `\"Unkown\"` elements as a job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_deduplicated = ddf2.drop_duplicates(subset=['CleanJobTitle'])[['EmployerClean', 'CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle', 'years', 'weeks']].replace('Unknown', np.nan)\n",
    "# ddf_deduplicated2 = ddf_deduplicated[['EmployerClean', 'CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle', 'years', 'weeks']].replace('Unknown', np.nan)\n",
    "firm_full_sample = ddf_deduplicated.groupby('EmployerClean')[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()\n",
    "firm_year = ddf_deduplicated.groupby(['EmployerClean', 'years'])[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()\n",
    "firm_week = ddf_deduplicated.groupby(['EmployerClean', 'weeks'])[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check the resulf from the above you can run the computations by uncommenting the cell below. Please note that at the end of this notebook you will save csv files with the output from the above lines so you can examine the results later on as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.6 s, sys: 5.44 s, total: 57.1 s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# firm_full_sample, firm_year, firm_week = dask.compute(firm_full_sample, firm_year, firm_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployerClean</th>\n",
       "      <th>weeks</th>\n",
       "      <th>CleanJobTitle</th>\n",
       "      <th>ConsolidatedTitle</th>\n",
       "      <th>CanonJobTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31083</th>\n",
       "      <td>Zebra Technologies</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31084</th>\n",
       "      <td>Zenith</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31085</th>\n",
       "      <td>Zenith</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31086</th>\n",
       "      <td>Zenith</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31087</th>\n",
       "      <td>Zenith</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31178</th>\n",
       "      <td>inVentiv Health</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31179</th>\n",
       "      <td>inVentiv Health</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31180</th>\n",
       "      <td>inVentiv Health</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31181</th>\n",
       "      <td>inVentiv Health</td>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31182</th>\n",
       "      <td>inVentiv Health</td>\n",
       "      <td>52</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            EmployerClean  weeks  CleanJobTitle  ConsolidatedTitle  \\\n",
       "31083  Zebra Technologies     51              3                  3   \n",
       "31084              Zenith      1              5                  5   \n",
       "31085              Zenith      2              1                  1   \n",
       "31086              Zenith      5              1                  1   \n",
       "31087              Zenith      6              1                  1   \n",
       "...                   ...    ...            ...                ...   \n",
       "31178     inVentiv Health     48              4                  4   \n",
       "31179     inVentiv Health     49              5                  5   \n",
       "31180     inVentiv Health     50              2                  2   \n",
       "31181     inVentiv Health     51              7                  7   \n",
       "31182     inVentiv Health     52              7                  7   \n",
       "\n",
       "       CanonJobTitle  \n",
       "31083              3  \n",
       "31084              4  \n",
       "31085              0  \n",
       "31086              0  \n",
       "31087              0  \n",
       "...              ...  \n",
       "31178              3  \n",
       "31179              4  \n",
       "31180              1  \n",
       "31181              6  \n",
       "31182              6  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# firm_week.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meassure 4\n",
    "\n",
    "### Part 1 - Managerial intensity\n",
    "\n",
    "For each firm-location-week-occupation, calculate the number of job ads with the managerial job codes available in the dataset.\n",
    "\n",
    "Managerial roles are, almost exclusively, the only occupations that start with 11. With that in mind, we will pick all occupations that start with 11 as opposed to specific ones, to increase the speed at which we create the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first create our dummy occupation condition\n",
    "occu_condition = ddf2['BGTOcc'].str.startswith('11')\n",
    "\n",
    "# we will then assign it back into the dask dataframe\n",
    "managers_dummy_df = ddf2.assign(managerial_occu=occu_condition)\n",
    "\n",
    "# and finally filter in the managerial roles\n",
    "managers_only_df = managers_dummy_df[managers_dummy_df['managerial_occu'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's replace the Unknown placeholder again with np.nan\n",
    "managers_only_df1 = managers_only_df[['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', \n",
    "                                      'weeks', 'BGTOcc', 'CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].replace('Unknown', np.nan)\n",
    "\n",
    "# let's group a dataset with our variables of interest\n",
    "managers_group1 = managers_only_df1.groupby(['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', 'weeks', 'BGTOcc'])\n",
    "\n",
    "# and then let's count the jobs in our three job title variables\n",
    "individual_managers = managers_group1[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "For each firm-location-week-alloccups, calculate the number of job ads for all managerial roles (e.g. every occupation that starts with 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "managers_group2 = managers_only_df1.groupby(['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', 'weeks'])\n",
    "all_managers = managers_group2[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "For each firm-location-week, calculate the total number of job ads posted by that firm regardless of the occupation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf3 = ddf2[['EmployerClean', 'CleanJobTitle', 'ConsolidatedTitle', \n",
    "             'CanonJobTitle', 'years', 'weeks', 'CanonState', \n",
    "             'CanonCounty', 'CanonPostalCode']].replace('Unknown', np.nan)\n",
    "\n",
    "firm_loc_week_group = ddf3.groupby(['EmployerClean', 'CanonState', 'CanonCounty', 'CanonPostalCode', 'weeks'])\n",
    "\n",
    "firm_loc_week_df = firm_loc_week_group[['CleanJobTitle', 'ConsolidatedTitle', 'CanonJobTitle']].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to check the result from the above cells you can run the computations by uncommenting the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.2 s, sys: 13.1 s, total: 56.3 s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "individual_managers, all_managers, firm_loc_week_df = dask.compute(individual_managers, all_managers, firm_loc_week_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployerClean</th>\n",
       "      <th>CanonState</th>\n",
       "      <th>CanonCounty</th>\n",
       "      <th>CanonPostalCode</th>\n",
       "      <th>weeks</th>\n",
       "      <th>CleanJobTitle</th>\n",
       "      <th>ConsolidatedTitle</th>\n",
       "      <th>CanonJobTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-800-Flowers.com</td>\n",
       "      <td>NY</td>\n",
       "      <td>Nassau</td>\n",
       "      <td>11514</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170 Systems</td>\n",
       "      <td>MA</td>\n",
       "      <td>Middlesex</td>\n",
       "      <td>01730</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st Lake Properties</td>\n",
       "      <td>LA</td>\n",
       "      <td>Jefferson</td>\n",
       "      <td>70001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1st Lake Properties</td>\n",
       "      <td>MS</td>\n",
       "      <td>Madison</td>\n",
       "      <td>39158</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24 Hour Fitness</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Maricopa</td>\n",
       "      <td>85013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         EmployerClean CanonState CanonCounty CanonPostalCode  weeks  \\\n",
       "0    1-800-Flowers.com         NY      Nassau           11514      2   \n",
       "1          170 Systems         MA   Middlesex           01730      2   \n",
       "2  1st Lake Properties         LA   Jefferson           70001      1   \n",
       "3  1st Lake Properties         MS     Madison           39158      1   \n",
       "4      24 Hour Fitness         AZ    Maricopa           85013      1   \n",
       "\n",
       "   CleanJobTitle  ConsolidatedTitle  CanonJobTitle  \n",
       "0              1                  1              0  \n",
       "1              1                  1              1  \n",
       "2              2                  2              2  \n",
       "3              1                  1              1  \n",
       "4              1                  1              0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firm_loc_week_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all Files\n",
    "\n",
    "The following function will help you save a csv file with the following characteristics:\n",
    "- choose between 1 or many datasets for the output of your measure\n",
    "- create a new directory for this output, based on the `path_out` variable provided at the beginning of this notebook\n",
    "- add a name for your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv_files(new_dir_name, data, new_file_name, pandas_or_dask=True, partitions=None):\n",
    "    \n",
    "    if not os.path.exists(os.path.join(path_out, new_dir_name)):\n",
    "        os.makedirs(os.path.join(path_out, new_dir_name))\n",
    "\n",
    "    if pandas_or_dask == True:\n",
    "        data = data.compute()\n",
    "        data.to_csv(os.path.join(path_out, new_dir_name, f'{new_file_name}.csv'), index=False)\n",
    "    else:\n",
    "        # the following lines of code will take the last dataset, repartition it,\n",
    "        # and save it to the desired location. Notice the wildcard \"*\" below. That is\n",
    "        # the spot Dask will use to number your files starting from 0\n",
    "        (data\n",
    "         .repartition(npartitions=partitions)\n",
    "         .to_csv(os.path.join(path_out, new_dir_name, f'{new_file_name}*.csv'), index=False)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33min 53s, sys: 28min 31s, total: 1h 2min 24s\n",
      "Wall time: 1h 31min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "save_csv_files(new_dir_name='measure_3/', data=firm_full_sample,    new_file_name='firm_full_sample',    pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_3/', data=firm_year,           new_file_name='firm_year',           pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_3/', data=firm_week,           new_file_name='firm_week',           pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_4/', data=individual_managers, new_file_name='individual_managers', pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_4/', data=all_managers,        new_file_name='all_managers',        pandas_or_dask=True)\n",
    "save_csv_files(new_dir_name='measure_4/', data=firm_loc_week_df,    new_file_name='firm_loc_week_df',    pandas_or_dask=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
